{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from subprocess import check_call\n",
    "from typing import Any, Callable, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from lightly.transforms import SimCLRTransform\n",
    "from numpy.lib.npyio import NpzFile\n",
    "from numpy.random import Generator\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST, VisionDataset\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from lightly.data import LightlyDataset\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from itertools import chain\n",
    "from models import ConvNet\n",
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "from lightly.loss import NTXentLoss\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "dataset = partial(MNIST, root=Path(\"mnist_data\"), download=True)\n",
    "train_set = dataset(train=True)  # Loads the training set\n",
    "test_set = dataset(train=False)  # Loads the test set\n",
    "\n",
    "train_transform = SimCLRTransform(\n",
    "    input_size=28,\n",
    "    min_scale=0.5,\n",
    "    hf_prob=0,\n",
    "    rr_prob=0,\n",
    "    vf_prob=0,\n",
    "    normalize=dict(mean=[0.1307], std=[0.3081]),\n",
    ")\n",
    "\n",
    "test_transform = Compose([ToTensor(), Normalize(mean=[0.1307], std=[0.3081])])\n",
    "\n",
    "# Step 1: Transform the train and test sets with the respective transformations\n",
    "train_set = LightlyDataset.from_torch_dataset(train_set, transform=train_transform)\n",
    "test_set = LightlyDataset.from_torch_dataset(test_set, transform=test_transform)\n",
    "\n",
    "# Step 2: Create DataLoader for both train and test sets\n",
    "train_loader = DataLoader(train_set, batch_size=1_024, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1_024, shuffle=False)\n",
    "\n",
    "# Step 3: Define the encoder (ConvNet)\n",
    "encoder = ConvNet(input_shape=[28, 28], output_size=128)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Step 4: Define the projection head (SimCLRProjectionHead)\n",
    "proj_head = SimCLRProjectionHead(input_dim=128, hidden_dim=512)\n",
    "proj_head = proj_head.to(device)\n",
    "\n",
    "# Step 5: Define the loss function (NTXentLoss)\n",
    "loss_fn = NTXentLoss()\n",
    "\n",
    "# Step 6: Set up the optimizer\n",
    "params = chain(encoder.parameters(), proj_head.parameters())\n",
    "optimizer = SGD(params, lr=1, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def get_next(dataloader: DataLoader) -> Union[Tensor, Tuple]:\n",
    "    try:\n",
    "        return next(dataloader)\n",
    "    except:\n",
    "        dataloader = iter(dataloader)\n",
    "        return next(dataloader)\n",
    "\n",
    "def save_table(path: Union[Path, str], table: DataFrame, formatting: dict) -> None:\n",
    "    for key in formatting:\n",
    "        if key in table:\n",
    "            table[key] = table[key].apply(formatting[key])\n",
    "\n",
    "    table.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 7.007874011993408\n",
      "Step 1: loss = 6.918391704559326\n",
      "Step 2: loss = 7.011937141418457\n",
      "Step 3: loss = 7.296550750732422\n",
      "Step 4: loss = 7.077115535736084\n",
      "Step 5: loss = 6.87874698638916\n",
      "Step 6: loss = 6.914821624755859\n",
      "Step 7: loss = 6.848741054534912\n",
      "Step 8: loss = 6.859347820281982\n",
      "Step 9: loss = 6.8735151290893555\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "steps, losses = [], []\n",
    "n_optim_steps = 10\n",
    "\n",
    "for step in range(n_optim_steps):\n",
    "    (inputs_0, inputs_1), _, _ = get_next(train_loader)\n",
    "\n",
    "    embeddings_0 = proj_head(encoder(inputs_0.to(device)))\n",
    "    embeddings_1 = proj_head(encoder(inputs_1.to(device)))\n",
    "\n",
    "    loss = loss_fn(embeddings_0, embeddings_1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    steps += [step]\n",
    "    losses += [loss.item()]\n",
    "    print(f\"Step {step}: loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving results...\")\n",
    "train_log = pd.DataFrame({\"step\": steps, \"loss\": losses})\n",
    "formatting = {\"loss\": \"{:.4f}\".format}\n",
    "save_table(\"train_encoders/pretraining.csv\", train_log, formatting)\n",
    "\n",
    "torch.save(encoder.state_dict(), \"train_encoders/encoder.pth\")\n",
    "torch.save(proj_head.state_dict(), \"train_encoders/projection_head.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
